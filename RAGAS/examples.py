"""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã.
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.
"""

import os
import sys
import yaml
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.pipeline import create_rag_pipeline, RAGPipelineManager
from src.evaluation import create_evaluator
from src.data_processing import create_data_processor
from src.models import create_model_manager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def example_basic_usage():
    """–ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã."""
    print("=" * 60)
    print("–ü–†–ò–ú–ï–† 1: –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/base_config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    print("–°–æ–∑–¥–∞–Ω–∏–µ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞...")
    pipeline = create_rag_pipeline(config)
    pipeline.initialize()
    
    # –ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å—ã
    questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        "–ö–∞–∫–∏–µ —Ç–∏–ø—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å—É—â–µ—Å—Ç–≤—É—é—Ç?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫?"
    ]
    
    print("\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞:")
    for question in questions:
        print(f"\n–í–æ–ø—Ä–æ—Å: {question}")
        result = pipeline.query(question)
        print(f"–û—Ç–≤–µ—Ç: {result['answer'][:200]}...")
        print(f"–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {result['response_time']:.2f} —Å–µ–∫")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = pipeline.get_stats()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞:")
    for stat_name, stat_value in stats.items():
        print(f"  {stat_name}: {stat_value}")


def example_evaluation():
    """–ü—Ä–∏–º–µ—Ä –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã."""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 2: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/base_config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    pipeline = create_rag_pipeline(config)
    pipeline.initialize()
    
    evaluator = create_evaluator(config)
    data_processor = create_data_processor(config)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    qa_dataset = data_processor.load_qa_dataset('data/russian_qa_dataset.json')
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(qa_dataset)} –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
    print("–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏...")
    evaluation_results = evaluator.evaluate_pipeline(pipeline, qa_dataset)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    for metric, value in evaluation_results['metrics'].items():
        if metric.endswith('_mean'):
            print(f"  {metric}: {value:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    evaluator.save_results(evaluation_results, 'results/example_evaluation.json')
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/example_evaluation.json")


def example_multiple_pipelines():
    """–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏."""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 3: –†–∞–±–æ—Ç–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
    manager = RAGPipelineManager()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    configs = {
        'base': 'config/base_config.yaml',
        'gpu': 'config/gpu_config.yaml',
        'cpu': 'config/cpu_config.yaml'
    }
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω—ã
    for name, config_path in configs.items():
        if os.path.exists(config_path):
            print(f"–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞: {name}")
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            manager.add_pipeline(name, config)
        else:
            print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config_path}")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
    manager.set_active_pipeline('base')
    active_pipeline = manager.get_active_pipeline()
    
    if active_pipeline:
        print(f"\n–ê–∫—Ç–∏–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: base")
        result = active_pipeline.query("–ß—Ç–æ —Ç–∞–∫–æ–µ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ?")
        print(f"–û—Ç–≤–µ—Ç: {result['answer'][:200]}...")
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
    print(f"\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã: {manager.list_pipelines()}")


def example_custom_configuration():
    """–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 4: –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    custom_config = {
        'experiment': {
            'name': 'custom_experiment',
            'description': '–ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –æ—Å–æ–±—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏',
            'tags': ['custom', 'example']
        },
        'data': {
            'input_path': 'data/documents',
            'dataset_path': 'data/russian_qa_dataset.json',
            'chunk_size': 500,
            'chunk_overlap': 100,
            'text_splitter': 'recursive'
        },
        'models': {
            'embedding': {
                'name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                'device': 'auto',
                'normalize_embeddings': True
            },
            'generator': {
                'name': 'microsoft/DialoGPT-small',
                'device': 'auto',
                'max_length': 256,
                'temperature': 0.8,
                'do_sample': True
            }
        },
        'vector_store': {
            'type': 'chroma',
            'persist_directory': 'data/vector_db_custom',
            'collection_name': 'custom_documents'
        },
        'retriever': {
            'k': 3,
            'search_type': 'similarity',
            'fetch_k': 10
        },
        'evaluation': {
            'metrics': ['cosine_similarity', 'rouge'],
            'batch_size': 4,
            'save_predictions': True
        },
        'mlflow': {
            'experiment_name': 'Custom_Experiments',
            'tracking_uri': 'file:./mlruns',
            'log_artifacts': True,
            'log_models': True
        },
        'web': {
            'interface': 'gradio',
            'port': 7860,
            'host': '0.0.0.0',
            'share': False
        },
        'logging': {
            'level': 'INFO',
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            'file': 'logs/custom_experiment.log'
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_path = 'config/custom_config.yaml'
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(custom_config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"–ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {config_path}")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    pipeline = create_rag_pipeline(custom_config)
    pipeline.initialize()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º
    result = pipeline.query("–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?")
    print(f"–û—Ç–≤–µ—Ç: {result['answer'][:200]}...")


def example_model_comparison():
    """–ü—Ä–∏–º–µ—Ä —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 5: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    print("=" * 60)
    
    # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    embedding_models = [
        'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'sentence-transformers/distiluse-base-multilingual-cased'
    ]
    
    generator_models = [
        'microsoft/DialoGPT-small',
        'microsoft/DialoGPT-medium'
    ]
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/base_config.yaml', 'r', encoding='utf-8') as f:
        base_config = yaml.safe_load(f)
    
    test_question = "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
    
    print(f"–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: {test_question}")
    print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:")
    
    for emb_model in embedding_models:
        for gen_model in generator_models:
            print(f"\n--- Embedding: {emb_model.split('/')[-1]} | Generator: {gen_model.split('/')[-1]} ---")
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –Ω–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            config = base_config.copy()
            config['models']['embedding']['name'] = emb_model
            config['models']['generator']['name'] = gen_model
            config['experiment']['name'] = f"comparison_{emb_model.split('/')[-1]}_{gen_model.split('/')[-1]}"
            
            try:
                # –°–æ–∑–¥–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω
                pipeline = create_rag_pipeline(config)
                pipeline.initialize()
                
                result = pipeline.query(test_question)
                print(f"–û—Ç–≤–µ—Ç: {result['answer'][:150]}...")
                print(f"–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {result['response_time']:.2f} —Å–µ–∫")
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞: {str(e)[:100]}...")


def example_batch_processing():
    """–ü—Ä–∏–º–µ—Ä –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤."""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 6: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/base_config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = create_rag_pipeline(config)
    pipeline.initialize()
    
    # –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    batch_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        "–ö–∞–∫–∏–µ —Ç–∏–ø—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å—É—â–µ—Å—Ç–≤—É—é—Ç?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ?",
        "–ö–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        "–ö–∞–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ ML?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ?"
    ]
    
    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(batch_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤...")
    
    # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    results = pipeline.batch_query(batch_questions)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    response_times = [r['response_time'] for r in results]
    avg_time = sum(response_times) / len(response_times)
    total_time = sum(response_times)
    
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"  –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(batch_questions)}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_time:.2f} —Å–µ–∫")
    print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
    print(f"  –í–æ–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {len(batch_questions) / total_time:.2f}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
    print(f"\n–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:")
    for i, result in enumerate(results[:3]):
        print(f"\n{i+1}. –í–æ–ø—Ä–æ—Å: {result['question']}")
        print(f"   –û—Ç–≤–µ—Ç: {result['answer'][:100]}...")
        print(f"   –í—Ä–µ–º—è: {result['response_time']:.2f} —Å–µ–∫")


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤."""
    print("üöÄ –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø RAG –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs('logs', exist_ok=True)
        os.makedirs('results', exist_ok=True)
        os.makedirs('data', exist_ok=True)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        example_basic_usage()
        example_evaluation()
        example_multiple_pipelines()
        example_custom_configuration()
        example_model_comparison()
        example_batch_processing()
        
        print("\n" + "=" * 60)
        print("‚úÖ –í–°–ï –ü–†–ò–ú–ï–†–´ –í–´–ü–û–õ–ù–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤: {e}")
        logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")


if __name__ == "__main__":
    main()


#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
"""

import yaml
import json
import time
import logging
import numpy as np
import os
import random
from typing import Dict, List, Any
from pathlib import Path
import mlflow
import mlflow.sklearn
from tqdm import tqdm
import optuna
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleHyperparameterOptimizer:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    
    def __init__(self, base_config_path: str, experiment_name: str = "Hyperparameter_Optimization_Results"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
        self.base_config_path = base_config_path
        self.experiment_name = experiment_name
        self.base_config = self._load_config(base_config_path)
        self.best_score = 0.0
        self.best_params = None
        self.trial_results = []
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
        try:
            mlflow.set_experiment(experiment_name)
            logger.info(f"üìä MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω: {experiment_name}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {e}")
            try:
                mlflow.create_experiment(experiment_name)
                mlflow.set_experiment(experiment_name)
                logger.info(f"üìä MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –≤—Ä—É—á–Ω—É—é: {experiment_name}")
            except Exception as e2:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {e2}")
        
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _save_config(self, config: Dict, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        with open(path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    def _create_trial_config(self, trial: optuna.Trial) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏—Å–ø—ã—Ç–∞–Ω–∏—è"""
        config = self.base_config.copy()
        
        # === –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–´ –î–õ–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ===
        
        # 1. –í–µ—Å–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        semantic_weight = trial.suggest_float('semantic_weight', 0.3, 0.9, step=0.1)
        bm25_weight = 1.0 - semantic_weight
        
        # 2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        semantic_k = trial.suggest_int('semantic_k', 8, 20, step=2)
        bm25_k = trial.suggest_int('bm25_k', 8, 20, step=2)
        final_k = trial.suggest_int('final_k', 3, 10, step=1)
        
        # 3. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã BM25
        bm25_k1 = trial.suggest_float('bm25_k1', 0.8, 2.0, step=0.1)
        bm25_b = trial.suggest_float('bm25_b', 0.5, 1.0, step=0.05)
        
        # 4. –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤
        chunk_size = trial.suggest_categorical('chunk_size', [300, 400, 500, 600, 700, 800])
        chunk_overlap = trial.suggest_int('chunk_overlap', 30, 100, step=10)
        
        # 5. –¢–∏–ø –ø–æ–∏—Å–∫–∞
        search_type = trial.suggest_categorical('search_type', ['hybrid', 'similarity', 'bm25'])
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if 'hybrid_search' in config:
            config['hybrid_search']['semantic_weight'] = semantic_weight
            config['hybrid_search']['bm25_weight'] = bm25_weight
            config['hybrid_search']['semantic_k'] = semantic_k
            config['hybrid_search']['bm25_k'] = bm25_k
            config['hybrid_search']['final_k'] = final_k
            config['hybrid_search']['bm25_k1'] = bm25_k1
            config['hybrid_search']['bm25_b'] = bm25_b
        
        config['retriever']['search_type'] = search_type
        config['retriever']['k'] = final_k
        
        config['text_splitter']['chunk_size'] = chunk_size
        config['text_splitter']['chunk_overlap'] = chunk_overlap
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è
        config['trial_number'] = trial.number
        config['trial_params'] = {
            'semantic_weight': semantic_weight,
            'bm25_weight': bm25_weight,
            'semantic_k': semantic_k,
            'bm25_k': bm25_k,
            'final_k': final_k,
            'bm25_k1': bm25_k1,
            'bm25_b': bm25_b,
            'chunk_size': chunk_size,
            'chunk_overlap': chunk_overlap,
            'search_type': search_type
        }
        
        return config
    
    def _run_single_test(self, config: Dict, max_samples: int = 50) -> Dict:
        """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ RAG —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            temp_config_path = f"temp_config_trial_{config['trial_number']}.yaml"
            self._save_config(config, temp_config_path)
            
            # –ò–º–ø–æ—Ä—Ç –∏ –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –Ω–∞–ø—Ä—è–º—É—é
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
            
            from src.pipeline import create_rag_pipeline
            from src.dataset_loader import create_dataset_loader
            from src.evaluation import RAGEvaluator
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            dataset_loader = create_dataset_loader(config)
            evaluator = RAGEvaluator(config)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
            datasets_config = config.get('datasets', {})
            dataset_name = list(datasets_config.keys())[0]
            dataset_config = datasets_config[dataset_name]
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ QA –ø–∞—Ä
            qa_pairs_file = dataset_config['qa_pairs_file']
            dataset_path = dataset_config['path']
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            if os.path.isabs(qa_pairs_file):
                qa_pairs_path = qa_pairs_file
            else:
                # –ï—Å–ª–∏ –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
                if os.path.isabs(dataset_path):
                    qa_pairs_path = os.path.join(dataset_path, qa_pairs_file)
                else:
                    qa_pairs_path = os.path.join(os.path.dirname(__file__), dataset_path, qa_pairs_file)
            
            with open(qa_pairs_path, 'r', encoding='utf-8') as f:
                qa_pairs = json.load(f)
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ 100 —Å–µ–º–ø–ª–æ–≤)
            max_samples = 100
            if len(qa_pairs) > max_samples:
                # –§–∏–∫—Å–∏—Ä—É–µ–º —Å–µ–º–ø–ª—ã –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
                qa_pairs = qa_pairs[:max_samples]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
            pipeline = create_rag_pipeline(config)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
            pipeline.initialize()
            
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            results = evaluator.evaluate_pipeline(pipeline, qa_pairs)
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            Path(temp_config_path).unlink()
            
            return {
                'success': True,
                'metrics': results['metrics'],
                'total_samples': results['total_samples']
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            return {
                'success': False,
                'error': str(e),
                'metrics': {}
            }
    
    def _objective(self, trial: optuna.Trial) -> float:
        """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∏—Å–ø—ã—Ç–∞–Ω–∏—è
            config = self._create_trial_config(trial)
            
            # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
            test_result = self._run_single_test(config, max_samples=50)
            
            if not test_result['success']:
                logger.error(f"‚ùå –¢–µ—Å—Ç –Ω–µ —É–¥–∞–ª—Å—è –¥–ª—è –∏—Å–ø—ã—Ç–∞–Ω–∏—è {trial.number}: {test_result.get('error', 'Unknown error')}")
                return 0.0
            
            metrics = test_result['metrics']
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–∏
            mrr = metrics.get('retriever_mrr_mean', 0.0)
            precision = metrics.get('retriever_precision_mean', 0.0)
            recall = metrics.get('retriever_recall_mean', 0.0)
            ndcg = metrics.get('retriever_ndcg_mean', 0.0)
            hit_rate = metrics.get('retriever_hit_rate_mean', 0.0)
            retrieval_time = metrics.get('retrieval_time_mean', 1.0)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            quality_score = 0.4 * mrr + 0.2 * precision + 0.2 * recall + 0.1 * ndcg + 0.1 * hit_rate
            time_penalty = min(0.1, retrieval_time * 0.01)
            final_score = quality_score - time_penalty
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow
            with mlflow.start_run(run_name=f"trial_{trial.number}"):
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                for param_name, param_value in config['trial_params'].items():
                    mlflow.log_param(param_name, param_value)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                mlflow.log_metric("objective_score", final_score)
                mlflow.log_metric("mrr", mrr)
                mlflow.log_metric("precision", precision)
                mlflow.log_metric("recall", recall)
                mlflow.log_metric("ndcg", ndcg)
                mlflow.log_metric("hit_rate", hit_rate)
                mlflow.log_metric("retrieval_time", retrieval_time)
                mlflow.log_metric("quality_score", quality_score)
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                mlflow.log_text(yaml.dump(config, default_flow_style=False), "config.yaml")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å–ø—ã—Ç–∞–Ω–∏—è
            trial_result = {
                'trial_number': trial.number,
                'params': config['trial_params'],
                'metrics': metrics,
                'objective_score': final_score,
                'quality_score': quality_score,
                'timestamp': datetime.now().isoformat()
            }
            self.trial_results.append(trial_result)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if final_score > self.best_score:
                self.best_score = final_score
                self.best_params = config['trial_params'].copy()
                logger.info(f"üèÜ –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –û—Ü–µ–Ω–∫–∞: {final_score:.4f}")
                logger.info(f"üìä MRR: {mrr:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}")
            
            logger.info(f"‚úÖ –ò—Å–ø—ã—Ç–∞–Ω–∏–µ {trial.number} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û—Ü–µ–Ω–∫–∞: {final_score:.4f}")
            
            return final_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∏—Å–ø—ã—Ç–∞–Ω–∏–∏ {trial.number}: {e}")
            return 0.0
    
    def optimize(self, n_trials: int = 10, timeout: int = 1800):
        """–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        random.seed(42)
        np.random.seed(42)
        
        logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞")
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π: {n_trials}")
        logger.info(f"‚è∞ –¢–∞–π–º–∞—É—Ç: {timeout} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üé≤ Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: 42 (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–º–ø–ª—ã)")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è Optuna
        study = optuna.create_study(
            direction='maximize',
            sampler=optuna.samplers.TPESampler(seed=42),
            pruner=optuna.pruners.MedianPruner(
                n_startup_trials=3,
                n_warmup_steps=2,
                interval_steps=1
            )
        )
        
        # –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        logger.info("üîç –ó–∞–ø—É—Å–∫ –±–∞–π–µ—Å–æ–≤—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ –¥–ª—è –∏—Å–ø—ã—Ç–∞–Ω–∏–π
        pbar = tqdm(total=n_trials, desc="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è", unit="–∏—Å–ø—ã—Ç–∞–Ω–∏–µ")
        
        def objective_with_progress(trial):
            result = self._objective(trial)
            pbar.update(1)
            pbar.set_postfix({
                'best_score': f"{self.best_score:.4f}",
                'current_score': f"{result:.4f}"
            })
            return result
        
        try:
            study.optimize(
                objective_with_progress,
                n_trials=n_trials,
                timeout=timeout,
                show_progress_bar=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            )
        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
        finally:
            pbar.close()
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._analyze_optimization_results(study)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._save_optimization_results(study)
        
        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def _analyze_optimization_results(self, study: optuna.Study):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        logger.info("\n" + "="*80)
        logger.info("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
        logger.info("="*80)
        
        if not study.trials:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å–ø—ã—Ç–∞–Ω–∏—è–º
        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
        logger.info(f"üìà –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π: {len(completed_trials)}")
        logger.info(f"üìà –ü—Ä–µ—Ä–≤–∞–Ω–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π: {len(study.trials) - len(completed_trials)}")
        
        if completed_trials:
            # –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            best_trial = study.best_trial
            logger.info(f"\nüèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
            logger.info(f"   –û—Ü–µ–Ω–∫–∞: {best_trial.value:.4f}")
            logger.info(f"   –ò—Å–ø—ã—Ç–∞–Ω–∏–µ: {best_trial.number}")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
            for param, value in best_trial.params.items():
                logger.info(f"     {param}: {value}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ü–µ–Ω–∫–∞–º
            scores = [t.value for t in completed_trials if t.value is not None]
            if scores:
                logger.info(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –û–¶–ï–ù–ö–ê–ú:")
                logger.info(f"   –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {np.mean(scores):.4f}")
                logger.info(f"   –ú–µ–¥–∏–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {np.median(scores):.4f}")
                logger.info(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {np.std(scores):.4f}")
                logger.info(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {np.min(scores):.4f}")
                logger.info(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {np.max(scores):.4f}")
    
    def _save_optimization_results(self, study: optuna.Study):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        results_path = "results/simple_hyperparameter_optimization_results.json"
        Path("results").mkdir(exist_ok=True)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        results_data = {
            'optimization_info': {
                'experiment_name': self.experiment_name,
                'base_config_path': self.base_config_path,
                'total_trials': len(study.trials),
                'completed_trials': len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),
                'best_score': self.best_score,
                'best_params': self.best_params,
                'optimization_time': datetime.now().isoformat()
            },
            'study_results': {
                'best_trial': {
                    'number': study.best_trial.number,
                    'value': study.best_trial.value,
                    'params': study.best_trial.params
                } if study.best_trial else None,
                'all_trials': [
                    {
                        'number': trial.number,
                        'value': trial.value,
                        'params': trial.params,
                        'state': trial.state.name
                    }
                    for trial in study.trials
                ]
            },
            'trial_results': self.trial_results
        }
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ numpy —Ç–∏–ø–æ–≤
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è numpy —Ç–∏–ø–æ–≤
        results_data = convert_numpy_types(results_data)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_path}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ª—É—á—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if self.best_params:
            best_config = self.base_config.copy()
            best_config.update({
                'hybrid_search': {
                    **best_config.get('hybrid_search', {}),
                    'semantic_weight': self.best_params['semantic_weight'],
                    'bm25_weight': self.best_params['bm25_weight'],
                    'semantic_k': self.best_params['semantic_k'],
                    'bm25_k': self.best_params['bm25_k'],
                    'final_k': self.best_params['final_k'],
                    'bm25_k1': self.best_params['bm25_k1'],
                    'bm25_b': self.best_params['bm25_b']
                },
                'retriever': {
                    **best_config.get('retriever', {}),
                    'search_type': self.best_params['search_type'],
                    'k': self.best_params['final_k']
                },
                'text_splitter': {
                    **best_config.get('text_splitter', {}),
                    'chunk_size': self.best_params['chunk_size'],
                    'chunk_overlap': self.best_params['chunk_overlap']
                }
            })
            
            best_config_path = "config/best_simple_retriever_config.yaml"
            self._save_config(best_config, best_config_path)
            logger.info(f"üèÜ –õ—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {best_config_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞")
    parser.add_argument("--config", default="config/hybrid_cpu_config.yaml", 
                       help="–ü—É—Ç—å –∫ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--n-trials", type=int, default=10,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—ã—Ç–∞–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    parser.add_argument("--timeout", type=int, default=1800,
                       help="–¢–∞–π–º–∞—É—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    parser.add_argument("--experiment-name", default="Simple_Retriever_Optimization",
                       help="–ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ MLflow")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    optimizer = SimpleHyperparameterOptimizer(args.config, args.experiment_name)
    
    # –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    optimizer.optimize(n_trials=args.n_trials, timeout=args.timeout)

if __name__ == "__main__":
    main()
